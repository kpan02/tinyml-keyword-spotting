{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-HW-SYS/a2/blob/main/3_training_and_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2nGDz0JliKU"
      },
      "source": [
        "# **3. Training and Testing**\n",
        "Please start early! Section 3.6 Training may take one to two hours to run. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5U9gkiTnC4s"
      },
      "source": [
        "## 3.0 Setup GDrive and Git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwcJax1zU04M"
      },
      "outputs": [],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQklidVMU0-t"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username    \n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bdUCGFEU1Es"
      },
      "outputs": [],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a2-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a2-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a2-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHXYdHkzU1MX"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6zMfxIflRLB"
      },
      "source": [
        "### GPU\n",
        "\n",
        "Ensure you are running the GPU runtime type:\n",
        "1.   Click \"Runtime\" on top banner\n",
        "2.   Select \"Change runtime type\"\n",
        "3.   Under \"Hardware accelarator\" select \"GPU\" and save\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be4rOan-nHrF"
      },
      "source": [
        "### Import code dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDDr3IrkliKY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Adding assignment 2 to the system path\n",
        "# -- make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "# Import libraries \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "# Import constants to use constants defined for training\n",
        "from src.constants import *\n",
        "# Import data_proc to use data processing functions\n",
        "import src.data_proc as data_proc\n",
        "\n",
        "random_seed = 0\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7qaF1IEliKa"
      },
      "source": [
        "## 3.1 Download and Preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLwsdGt_liKa"
      },
      "source": [
        "### Create audio processor\n",
        "This step is similar to what was done in part 2, so the files should already be downloaded in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdc42fZiliKa"
      },
      "outputs": [],
      "source": [
        "# Create audio_processor\n",
        "audio_processor = data_proc.AudioProcessor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e53768H0liKf"
      },
      "source": [
        "### Select device: cuda or cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrpzLHRhliKf"
      },
      "outputs": [],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device} to run the training scrpit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViruC2uOnY3u"
      },
      "source": [
        "## 3.2 Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qYQMncTliKb"
      },
      "outputs": [],
      "source": [
        "# Define train, test, and validation set\n",
        "train_set = audio_processor.data_index['training']\n",
        "test_set = audio_processor.data_index['testing']\n",
        "valid_set = audio_processor.data_index['validation']\n",
        "\n",
        "# Define data loaders\n",
        "from src.loaders import make_data_loaders\n",
        "data_loaders = make_data_loaders(audio_processor, device)\n",
        "train_loader = data_loaders['training']\n",
        "test_loader = data_loaders['testing']\n",
        "valid_loader = data_loaders['validation']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBSyrbs6liKg"
      },
      "source": [
        "## 3.3 Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OERV-lIDliKi"
      },
      "outputs": [],
      "source": [
        "from src.networks import TinyConv\n",
        "# Create a full precision (float32) TinyConv model\n",
        "model_fp32 = TinyConv(\n",
        "    model_settings=audio_processor.model_settings,\n",
        "    n_input=1,\n",
        "    n_output=audio_processor.num_labels\n",
        ")\n",
        "model_fp32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PeiCwmdliKk"
      },
      "source": [
        "## 3.4 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTDNIHCqliKj"
      },
      "outputs": [],
      "source": [
        "from src.train_val_test_utils import train, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnk6TOA8rv7C"
      },
      "source": [
        "### Adjust parameters\n",
        "*   You can change *n_epoch* to use a different number training steps/epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4twj3n1tliKk"
      },
      "outputs": [],
      "source": [
        "num_batches = len(train_loader)\n",
        "n_epoch = 50\n",
        "print(f'# batches: {num_batches} \\n# epochs: {n_epoch} \\n# total training steps: {num_batches * n_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps_AJaYKliKk"
      },
      "source": [
        "### Create optimizer for training\n",
        " Explore more at: \n",
        "[TORCH. OPTIM](https://pytorch.org/docs/stable/optim.html?highlight=torch%20optim%20lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqVXUQzYliKk"
      },
      "outputs": [],
      "source": [
        "from src.train_val_test_utils import create_optimizer\n",
        "\n",
        "# Create optimizer\n",
        "optimizer_fp32 = create_optimizer(model=model_fp32, learning_rate=0.001)\n",
        "print(optimizer_fp32.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX-iWv6Ash3R"
      },
      "source": [
        "### Train the model\n",
        "TensorBoard will allow you to visualize your results. The second code block, the training, will take a while to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGag-bchliKl"
      },
      "outputs": [],
      "source": [
        "pbar_update = 1 / (len(train_loader) + len(test_loader) + len(valid_loader))\n",
        "\n",
        "def run_training(model, data_loaders, n_epoch, optimizer,\n",
        "                 save_interval=1, resume=True, checkpoint_path=None):\n",
        "    test_loader = data_loaders['testing']\n",
        "    with tqdm(total=n_epoch) as pbar:\n",
        "      \n",
        "        completed_epoch = 1\n",
        "        if resume:\n",
        "            try:\n",
        "                #continue training with previous model if one exists\n",
        "                checkpoint = torch.load(checkpoint_path)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                completed_epoch = checkpoint[\"epoch\"] + 1\n",
        "                model.eval()\n",
        "                pbar.update(completed_epoch)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        last_valacc = 0\n",
        "        for epoch in range(completed_epoch, n_epoch + 1):\n",
        "            train_iters = len(data_loaders['training'])\n",
        "            \n",
        "            train(model, data_loaders, optimizer, \n",
        "                      epoch, device)\n",
        "            \n",
        "            valacc = test(valid_loader, model, device, epoch=epoch, \n",
        "                          loader_type='Valid', verbose=True)\n",
        "            #checkpoint the model every epoch\n",
        "            if epoch % save_interval == 0 and valacc > last_valacc:\n",
        "                last_valacc = valacc\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict()\n",
        "                }, checkpoint_path)\n",
        "                \n",
        "            # Update epoch pbar\n",
        "            pbar.update(1)\n",
        "        \n",
        "        testacc = test(test_loader, model, device, \n",
        "                     epoch=None, loader_type='Test')\n",
        "        print(f'Test Acc = {round(testacc,2)}%')\n",
        "\n",
        "\n",
        "# This is where your checkpoint file will be saved\n",
        "checkpoint_path = os.path.join(TORCH_DIR, \"fp32_checkpoint.pt\")\n",
        "\n",
        "model_fp32.to(device)\n",
        "run_training(\n",
        "    model=model_fp32, data_loaders=data_loaders, \n",
        "    n_epoch=n_epoch, optimizer=optimizer_fp32, \n",
        "    resume=True, checkpoint_path=checkpoint_path\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg1WlG-rliKl"
      },
      "source": [
        "## 3.5 Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYgFvfYAliKm"
      },
      "source": [
        "### Calculating accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PtKvJH_liKm"
      },
      "outputs": [],
      "source": [
        "from src.train_val_test_utils import plot_acc\n",
        "\n",
        "test_time_data_loaders = make_data_loaders(\n",
        "    audio_processor, device, \n",
        "    test_batch_size=1, valid_batch_size=1,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "plot_acc(\n",
        "    test_time_data_loaders['validation'], model_fp32, audio_processor, device,\n",
        "    \"validation\", 'float32 TinyConv', \"float\")\n",
        "plot_acc(\n",
        "    test_time_data_loaders['training'], model_fp32, audio_processor, device,\n",
        "    \"training\", 'float32 TinyConv', \"float\")\n",
        "acc = plot_acc(\n",
        "    test_time_data_loaders['testing'], model_fp32, audio_processor, device,\n",
        "    'testing', 'float32 TinyConv', \"float\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tMzxb-jliKm"
      },
      "source": [
        "## 3.6 Save the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqC6fEoUliKm"
      },
      "outputs": [],
      "source": [
        "def choose_name(model_name):\n",
        "    name = f\"{model_name}_\" + \"{index}\"\n",
        "    i = 0\n",
        "    while os.path.isfile(name.format(index=i)):\n",
        "        i += 1\n",
        "    name = name.format(index = i)\n",
        "    print(f\"The model's will be stored as: \\n {name}\")\n",
        "    return name\n",
        "\n",
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVKrP45aliKm"
      },
      "outputs": [],
      "source": [
        "# Choose a path\n",
        "# You can also define your own path\n",
        "model_name = f\"tinyconv_float32_init_seed{torch.initial_seed()}_{acc * 100:.2f}%\"\n",
        "file_name = choose_name(model_name)\n",
        "torch_path = os.path.join(TORCH_DIR, f'{file_name}.pt')\n",
        "torch_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHgqZ8yXliKn"
      },
      "outputs": [],
      "source": [
        "# Save the trained pytorch model to torch_path\n",
        "save_model(model_fp32, torch_path)\n",
        "'Saved!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnJHbwj0UAi5"
      },
      "outputs": [],
      "source": [
        "'You can now find your model in %s under the folder icon to the left.' % torch_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kauQRx68xaeo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "3_training_and_analysis.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "92bf126df007708fd70c442c808ee74575bedf7ea6317e0b182c3af0184af25d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
